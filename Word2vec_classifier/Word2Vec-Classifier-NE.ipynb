{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac2e86c",
   "metadata": {},
   "source": [
    "# Import data\n",
    "\n",
    "https://thinkingneuron.com/how-to-classify-text-using-word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1ae571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd6f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_df = pd.read_csv('QI NERs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "491a71e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "Government Agency     19\n",
      "National Lab          66\n",
      "Quantum_comp         428\n",
      "group_centre         229\n",
      "investor             459\n",
      "university           186\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advanced Materials And Process Engineering Lab...</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advancing Quantum Architecture Group</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ag Quantenoptik</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Institute of Materials Research and Engineering</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Force Research Laboratory Quantum Group</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name         Class\n",
       "0  Advanced Materials And Process Engineering Lab...  group_centre\n",
       "1               Advancing Quantum Architecture Group  group_centre\n",
       "2                                    Ag Quantenoptik  group_centre\n",
       "3    Institute of Materials Research and Engineering  group_centre\n",
       "4        Air Force Research Laboratory Quantum Group  group_centre"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(print(org_df.groupby('Class').size()))\n",
    "display(org_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c18958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "Government Agency     4\n",
      "National Lab         13\n",
      "Quantum_comp         86\n",
      "group_centre         46\n",
      "investor             92\n",
      "university           37\n",
      "dtype: int64\n",
      "Class\n",
      "Government Agency     15\n",
      "National Lab          53\n",
      "Quantum_comp         342\n",
      "group_centre         183\n",
      "investor             367\n",
      "university           149\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test = org_df.groupby(\"Class\").sample(frac=0.2, random_state=2)\n",
    "print(test.groupby('Class').size())\n",
    "train = org_df.drop(test.index)\n",
    "print(train.groupby('Class').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51769093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1387, 1592)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1517</th>\n",
       "      <th>180</th>\n",
       "      <th>1qbit</th>\n",
       "      <th>32</th>\n",
       "      <th>3i</th>\n",
       "      <th>415</th>\n",
       "      <th>500</th>\n",
       "      <th>5y</th>\n",
       "      <th>7percent</th>\n",
       "      <th>8vc</th>\n",
       "      <th>...</th>\n",
       "      <th>zhongtian</th>\n",
       "      <th>zte</th>\n",
       "      <th>zu</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zy4</th>\n",
       "      <th>zyvex</th>\n",
       "      <th>zürcher</th>\n",
       "      <th>zürich</th>\n",
       "      <th>école</th>\n",
       "      <th>Priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1517  180  1qbit  32  3i  415  500  5y  7percent  8vc  ...  zhongtian  zte  \\\n",
       "0     0    0      0   0   0    0    0   0         0    0  ...          0    0   \n",
       "1     0    0      0   0   0    0    0   0         0    0  ...          0    0   \n",
       "2     0    0      0   0   0    0    0   0         0    0  ...          0    0   \n",
       "3     0    0      0   0   0    0    0   0         0    0  ...          0    0   \n",
       "4     0    0      0   0   0    0    0   0         0    0  ...          0    0   \n",
       "\n",
       "   zu  zurich  zy4  zyvex  zürcher  zürich  école      Priority  \n",
       "0   0       0    0      0        0       0      0  group_centre  \n",
       "1   0       0    0      0        0       0      0  group_centre  \n",
       "2   0       0    0      0        0       0      0  group_centre  \n",
       "3   0       0    0      0        0       0      0  group_centre  \n",
       "4   0       0    0      0        0       0      0  group_centre  \n",
       "\n",
       "[5 rows x 1592 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count vectorization of text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "# Ticket Data\n",
    "corpus = org_df['name'].values\n",
    " \n",
    "# Creating the vectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    " \n",
    "# Converting the text to numeric data\n",
    "X = vectorizer.fit_transform(corpus)\n",
    " \n",
    "#print(vectorizer.get_feature_names())\n",
    " \n",
    "# Preparing Data frame For machine learning\n",
    "# Priority column acts as a target variable and other columns as predictors\n",
    "CountVectorizedData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "CountVectorizedData['Priority']=org_df['Class']\n",
    "print(CountVectorizedData.shape)\n",
    "CountVectorizedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275665d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "516ce649",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9dc8f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49387f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleModel = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b747355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff95575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function which takes text input and returns one vector for each sentence\n",
    "def FunctionText2Vec(inpTextData):\n",
    "    # Converting the text to numeric data\n",
    "    X = vectorizer.transform(inpTextData)\n",
    "    CountVecData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    # Creating empty dataframe to hold sentences\n",
    "    W2Vec_Data=pd.DataFrame()\n",
    "    \n",
    "    # Looping through each row for the data\n",
    "    for i in range(CountVecData.shape[0]):\n",
    "\n",
    "        # initiating a sentence with all zeros\n",
    "        Sentence = np.zeros(300)\n",
    "\n",
    "        # Looping thru each word in the sentence and if its present in \n",
    "        # the Word2Vec model then storing its vector\n",
    "        for word in WordsVocab[CountVecData.iloc[i,:] >=1]:\n",
    "            #print(word)\n",
    "            if word in GoogleModel:    \n",
    "                Sentence=Sentence+GoogleModel[word]\n",
    "        # Appending the sentence to the dataframe\n",
    "        W2Vec_Data=W2Vec_Data.append(pd.DataFrame([Sentence]))\n",
    "    return(W2Vec_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2fa9ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1517', '180', '1qbit', '32', '3i', '415', '500', '5y', '7percent',\n",
       "       '8vc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the list of words which are present in the Document term matrix\n",
    "WordsVocab=CountVectorizedData.columns[:-1]\n",
    " \n",
    "# Printing sample words\n",
    "WordsVocab[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aaf3a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1387, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the function to convert all the text data to Word2Vec Vectors\n",
    "W2Vec_Data=FunctionText2Vec(org_df['name'])\n",
    " \n",
    "# Checking the new representation for sentences\n",
    "W2Vec_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9bebefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1387, 1592)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizedData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22edea5d",
   "metadata": {},
   "source": [
    "# Prep Data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29b19201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>Priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.483643</td>\n",
       "      <td>0.641449</td>\n",
       "      <td>0.570801</td>\n",
       "      <td>0.213623</td>\n",
       "      <td>-0.491699</td>\n",
       "      <td>0.324738</td>\n",
       "      <td>0.412842</td>\n",
       "      <td>-0.856934</td>\n",
       "      <td>-0.431641</td>\n",
       "      <td>-0.374695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229370</td>\n",
       "      <td>-0.914062</td>\n",
       "      <td>1.146240</td>\n",
       "      <td>-0.153809</td>\n",
       "      <td>-0.227905</td>\n",
       "      <td>-0.166504</td>\n",
       "      <td>-0.301758</td>\n",
       "      <td>0.162598</td>\n",
       "      <td>0.095703</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.007812</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.252075</td>\n",
       "      <td>0.221313</td>\n",
       "      <td>-0.105732</td>\n",
       "      <td>-0.313965</td>\n",
       "      <td>0.133789</td>\n",
       "      <td>-1.097656</td>\n",
       "      <td>0.235565</td>\n",
       "      <td>0.316406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057129</td>\n",
       "      <td>-0.526611</td>\n",
       "      <td>-0.153076</td>\n",
       "      <td>0.240723</td>\n",
       "      <td>-0.083740</td>\n",
       "      <td>0.252686</td>\n",
       "      <td>-0.244141</td>\n",
       "      <td>0.192261</td>\n",
       "      <td>0.280457</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.148438</td>\n",
       "      <td>-0.010559</td>\n",
       "      <td>-0.066895</td>\n",
       "      <td>0.213867</td>\n",
       "      <td>-0.192383</td>\n",
       "      <td>-0.120117</td>\n",
       "      <td>0.063477</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>-0.208008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022949</td>\n",
       "      <td>0.118164</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.121094</td>\n",
       "      <td>0.267578</td>\n",
       "      <td>-0.126953</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.034668</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.337646</td>\n",
       "      <td>0.159912</td>\n",
       "      <td>0.450195</td>\n",
       "      <td>0.348389</td>\n",
       "      <td>0.128418</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.491943</td>\n",
       "      <td>-0.708008</td>\n",
       "      <td>-0.116211</td>\n",
       "      <td>-0.684570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256592</td>\n",
       "      <td>-0.881836</td>\n",
       "      <td>1.051758</td>\n",
       "      <td>0.207886</td>\n",
       "      <td>-0.454651</td>\n",
       "      <td>-0.149200</td>\n",
       "      <td>-0.305176</td>\n",
       "      <td>0.189453</td>\n",
       "      <td>0.131042</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.052002</td>\n",
       "      <td>-0.010101</td>\n",
       "      <td>0.633667</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>-0.142597</td>\n",
       "      <td>-0.339111</td>\n",
       "      <td>-0.011230</td>\n",
       "      <td>-1.048340</td>\n",
       "      <td>0.583954</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097961</td>\n",
       "      <td>-0.705078</td>\n",
       "      <td>0.359421</td>\n",
       "      <td>-0.032288</td>\n",
       "      <td>-0.517883</td>\n",
       "      <td>-0.020676</td>\n",
       "      <td>0.191406</td>\n",
       "      <td>-0.044678</td>\n",
       "      <td>-0.373657</td>\n",
       "      <td>group_centre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.483643  0.641449  0.570801  0.213623 -0.491699  0.324738  0.412842   \n",
       "1 -0.007812  0.004578  0.252075  0.221313 -0.105732 -0.313965  0.133789   \n",
       "2 -0.148438 -0.010559 -0.066895  0.213867 -0.192383 -0.120117  0.063477   \n",
       "3 -0.337646  0.159912  0.450195  0.348389  0.128418  0.156250  0.491943   \n",
       "4 -0.052002 -0.010101  0.633667 -0.110474 -0.142597 -0.339111 -0.011230   \n",
       "\n",
       "          7         8         9  ...       291       292       293       294  \\\n",
       "0 -0.856934 -0.431641 -0.374695  ... -0.229370 -0.914062  1.146240 -0.153809   \n",
       "1 -1.097656  0.235565  0.316406  ...  0.057129 -0.526611 -0.153076  0.240723   \n",
       "2  0.062500 -0.038086 -0.208008  ...  0.022949  0.118164  0.078125  0.121094   \n",
       "3 -0.708008 -0.116211 -0.684570  ... -0.256592 -0.881836  1.051758  0.207886   \n",
       "4 -1.048340  0.583954  0.002930  ... -0.097961 -0.705078  0.359421 -0.032288   \n",
       "\n",
       "        295       296       297       298       299      Priority  \n",
       "0 -0.227905 -0.166504 -0.301758  0.162598  0.095703  group_centre  \n",
       "1 -0.083740  0.252686 -0.244141  0.192261  0.280457  group_centre  \n",
       "2  0.267578 -0.126953  0.057373  0.187500  0.034668  group_centre  \n",
       "3 -0.454651 -0.149200 -0.305176  0.189453  0.131042  group_centre  \n",
       "4 -0.517883 -0.020676  0.191406 -0.044678 -0.373657  group_centre  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the target variable\n",
    "W2Vec_Data.reset_index(inplace=True, drop=True)\n",
    "W2Vec_Data['Priority']=CountVectorizedData['Priority']\n",
    " \n",
    "# Assigning to DataForML variable\n",
    "DataForML=W2Vec_Data\n",
    "DataForML.head()\n",
    "# DataForML = DataForML.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6c775d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       group_centre\n",
       "1       group_centre\n",
       "2       group_centre\n",
       "3       group_centre\n",
       "4       group_centre\n",
       "            ...     \n",
       "1382    Quantum_comp\n",
       "1383    Quantum_comp\n",
       "1384    Quantum_comp\n",
       "1385    Quantum_comp\n",
       "1386    Quantum_comp\n",
       "Name: Priority, Length: 1387, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizedData.Priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70bd417b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       group_centre\n",
       "1       group_centre\n",
       "2       group_centre\n",
       "3       group_centre\n",
       "4       group_centre\n",
       "            ...     \n",
       "1382    Quantum_comp\n",
       "1383    Quantum_comp\n",
       "1384    Quantum_comp\n",
       "1385    Quantum_comp\n",
       "1386    Quantum_comp\n",
       "Name: Priority, Length: 1387, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataForML.Priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f815a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a07b6d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1109, 300)\n",
      "(1109,)\n",
      "(278, 300)\n",
      "(278,)\n"
     ]
    }
   ],
   "source": [
    "# Separate Target Variable and Predictor Variables\n",
    "TargetVariable=DataForML.columns[-1]\n",
    "Predictors=DataForML.columns[:-1]\n",
    " \n",
    "X=DataForML[Predictors].values\n",
    "y=DataForML[TargetVariable].values\n",
    " \n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Sanity check for the sampled data\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7fa0656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1109, 300)\n",
      "(1109,)\n",
      "(278, 300)\n",
      "(278,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# Choose either standardization or Normalization\n",
    "# On this data Min Max Normalization is used because we need to fit Naive Bayes\n",
    " \n",
    "# Choose between standardization and MinMAx normalization\n",
    "#PredictorScaler=StandardScaler()\n",
    "PredictorScaler=MinMaxScaler()\n",
    " \n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    " \n",
    "# Generating the standardized values of X\n",
    "X=PredictorScalerFit.transform(X)\n",
    " \n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    " \n",
    "# Sanity check for the sampled data\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cbc95d",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa688b08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "National Lab       1.00      0.06      0.12        16\n",
      "Quantum_comp       0.58      0.78      0.66        94\n",
      "group_centre       0.64      0.71      0.67        49\n",
      "    investor       0.80      0.69      0.74        87\n",
      "  university       0.95      0.62      0.75        32\n",
      "\n",
      "    accuracy                           0.68       278\n",
      "   macro avg       0.79      0.57      0.59       278\n",
      "weighted avg       0.73      0.68      0.67       278\n",
      "\n",
      "[[ 1  9  3  3  0]\n",
      " [ 0 73 14  7  0]\n",
      " [ 0 11 35  2  1]\n",
      " [ 0 25  2 60  0]\n",
      " [ 0  8  1  3 20]]\n",
      "Accuracy of the model on Testing Sample Data: 0.67\n",
      "\n",
      "Accuracy values for 10-fold Cross Validation:\n",
      " [0.60449126 0.70438548 0.65423947 0.69113329 0.64253307 0.65258799\n",
      " 0.79026783 0.73554916 0.64297133 0.69716073]\n",
      "\n",
      "Final Average Accuracy of the model: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    " \n",
    "# GaussianNB is used in Binomial Classification\n",
    "# MultinomialNB is used in multi-class classification\n",
    "#clf = GaussianNB()\n",
    "clf = MultinomialNB()\n",
    " \n",
    "# Printing all the parameters of Naive Bayes\n",
    "# print(clf)\n",
    " \n",
    "NB=clf.fit(X_train,y_train)\n",
    "prediction=NB.predict(X_test)\n",
    " \n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction))\n",
    "print(metrics.confusion_matrix(y_test, prediction))\n",
    " \n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    " \n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    " \n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "Accuracy_Values=cross_val_score(NB, X , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225253d3",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad44003e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=15)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "National Lab       0.83      0.31      0.45        16\n",
      "Quantum_comp       0.57      0.99      0.73        94\n",
      "group_centre       0.81      0.61      0.70        49\n",
      "    investor       1.00      0.56      0.72        87\n",
      "  university       0.92      0.69      0.79        32\n",
      "\n",
      "    accuracy                           0.72       278\n",
      "   macro avg       0.83      0.63      0.68       278\n",
      "weighted avg       0.80      0.72      0.71       278\n",
      "\n",
      "[[ 5  7  4  0  0]\n",
      " [ 0 93  1  0  0]\n",
      " [ 0 18 30  0  1]\n",
      " [ 1 35  1 49  1]\n",
      " [ 0  9  1  0 22]]\n",
      "Accuracy of the model on Testing Sample Data: 0.71\n",
      "\n",
      "Accuracy values for 10-fold Cross Validation:\n",
      " [0.62208234 0.66877961 0.65063642 0.67941357 0.71114647 0.72464419\n",
      " 0.64749022 0.63049949 0.61051064 0.58333714]\n",
      "\n",
      "Final Average Accuracy of the model: 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=15)\n",
    " \n",
    "# Printing all the parameters of KNN\n",
    "print(clf)\n",
    " \n",
    "# Creating the model on Training Data\n",
    "KNN=clf.fit(X_train,y_train)\n",
    "prediction=KNN.predict(X_test)\n",
    " \n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction))\n",
    "print(metrics.confusion_matrix(y_test, prediction))\n",
    " \n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    " \n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "Accuracy_Values=cross_val_score(KNN, X , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))\n",
    " \n",
    "# Plotting the feature importance for Top 10 most important columns\n",
    "# There is no built-in method to get feature importance in KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738693ca",
   "metadata": {},
   "source": [
    "# Making predictions on New cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c50d4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining a function which converts words into numeric vectors for prediction\n",
    "def FunctionPredictUrgency(inpText):\n",
    "    \n",
    "    # Generating the Glove word vector embeddings\n",
    "    X=FunctionText2Vec(inpText)\n",
    "    #print(X)\n",
    "    \n",
    "    # If standardization/normalization was done on training\n",
    "    # then the above X must also be converted to same platform\n",
    "    # Generating the normalized values of X\n",
    "    X=PredictorScalerFit.transform(X)\n",
    "    \n",
    "    # Generating the prediction using Naive Bayes model and returning\n",
    "    Prediction=NB.predict(X)\n",
    "    Result=pd.DataFrame(data=inpText, columns=['Name'])\n",
    "    Result['Prediction']=Prediction\n",
    "    return(Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9499a206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wilfrid laurier university</td>\n",
       "      <td>university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nokia Bell Lab</td>\n",
       "      <td>investor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brookfield investments</td>\n",
       "      <td>investor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alphabet</td>\n",
       "      <td>Quantum_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arqit Quantum Inc</td>\n",
       "      <td>Quantum_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acme</td>\n",
       "      <td>Quantum_comp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name    Prediction\n",
       "0  wilfrid laurier university    university\n",
       "1              Nokia Bell Lab      investor\n",
       "2      Brookfield investments      investor\n",
       "3                    Alphabet  Quantum_comp\n",
       "4           Arqit Quantum Inc  Quantum_comp\n",
       "5                        Acme  Quantum_comp"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewTicket=[\"wilfrid laurier university\", \"Nokia Bell Lab\",\"Brookfield investments\", \"Alphabet\",\"Arqit Quantum Inc\",\"Acme\"]\n",
    "FunctionPredictUrgency(inpText=NewTicket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab7fbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9c289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1883b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# org_df.to_csv('NE_vectors3.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7aa62b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
